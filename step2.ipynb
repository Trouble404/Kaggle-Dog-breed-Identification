{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Loading data to gluon and obtain features of images\n",
    "** Extract features based on [Gluon Model Zoo](https://mxnet.incubator.apache.org/versions/master/api/python/gluon/model_zoo.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\MXNet\\lib\\site-packages\\mxnet-1.0.1-py2.7.egg\\mxnet\\optimizer.py:136: UserWarning: WARNING: New optimizer mxnet.optimizer.NAG is overriding existing optimizer mxnet.optimizer.NAG\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.data import vision\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# will make the plot outputs appear and be stored within the notebook.\n",
    "%matplotlib inline \n",
    "# define the wirte lengthy setting\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Image API in MXNet](https://mxnet.incubator.apache.org/api/python/image/image.html)**\n",
    "\n",
    "**[Gluon Data API](https://mxnet.incubator.apache.org/api/python/gluon/data.html?highlight=imagefolderdataset#mxnet.gluon.data.vision.ImageFolderDataset)**\n",
    "\n",
    "**[Fine-tuning: 通过微调来迁移学习](http://zh.gluon.ai/chapter_computer-vision/fine-tuning.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Define the pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu()\n",
    "\n",
    "preprocessing = [\n",
    "    image.ForceResizeAug((224,224)),\n",
    "    image.ColorNormalizeAug(mean=nd.array([0.485, 0.456, 0.406]), std=nd.array([0.229, 0.224, 0.225]))\n",
    "]\n",
    "\n",
    "def transform(data, label):\n",
    "    data = data.astype('float32') / 255\n",
    "    for pre in preprocessing:\n",
    "        data = pre(data)\n",
    "    \n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    return data, nd.array([label]).asscalar().astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 定义导出特征向量的函数define the output feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(net, data):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for X, y in tqdm(data):\n",
    "        feature = net.features(X.as_in_context(ctx))\n",
    "        features.append(feature.asnumpy())\n",
    "        labels.append(y.asnumpy())\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 obtain feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "preprocessing[0] = image.ForceResizeAug((224,224))\n",
    "imgs = vision.ImageFolderDataset('for_train',  flag=0, transform=None)\n",
    "data = gluon.data.DataLoader(imgs, 64)\n",
    "\n",
    "#features_vgg, labels = get_features(models.vgg16_bn(pretrained=True, ctx=ctx), data)\n",
    "#features_resnet, _ = get_features(models.resnet152_v1(pretrained=True, ctx=ctx), data)\n",
    "#features_densenet, _ = get_features(models.densenet161(pretrained=True, ctx=ctx), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.gluon.data.vision.datasets.ImageFolderDataset at 0x1b107080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:MXNet]",
   "language": "python",
   "name": "conda-env-MXNet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
